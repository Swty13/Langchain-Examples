{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8b66f773",
      "metadata": {
        "id": "8b66f773"
      },
      "source": [
        "# LangChain - Exploring the Features and Benefits of LangChain\n",
        "\n",
        "### Read : ðŸ¦œï¸ðŸ”—[LangChain-01: Introduction](https://medium.com/@sweety.tripathi13/%EF%B8%8F-langchain-01-introduction-27e5cbeaad64)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5dfe345",
      "metadata": {
        "id": "f5dfe345"
      },
      "source": [
        "#### Github Repo  : https://github.com/hwchase17/langchain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f098a316",
      "metadata": {
        "id": "f098a316"
      },
      "source": [
        "\n",
        "\n",
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0994f6",
      "metadata": {
        "id": "4e0994f6"
      },
      "outputs": [],
      "source": [
        "# pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e94e7cf4",
      "metadata": {
        "id": "e94e7cf4"
      },
      "source": [
        "## Modules\n",
        "\n",
        "###1.  Models\n",
        "\n",
        "Lang-chain allows you to swap easily between models. It enables access to a range of pre-trained LLMs from various providers ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e181be18",
      "metadata": {
        "id": "e181be18"
      },
      "source": [
        "###  OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f001e54",
      "metadata": {
        "id": "7f001e54"
      },
      "outputs": [],
      "source": [
        "# pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "124a516f",
      "metadata": {
        "id": "124a516f"
      },
      "outputs": [],
      "source": [
        "## Import Library\n",
        "## Setup keys\n",
        "\n",
        "import openai\n",
        "OPEN_AI_KEY = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "openai.api_key = OPEN_AI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a2fa2fc",
      "metadata": {
        "id": "1a2fa2fc"
      },
      "source": [
        "The **LLM class** is a class designed for interfacing with LLMs. There are lots of LLM providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ab03a2",
      "metadata": {
        "id": "05ab03a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981214f4-bf21-4e47-9e76-49e4145b97ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:WARNING! engine is not default parameter.\n",
            "                    engine was transferred to model_kwargs.\n",
            "                    Please confirm that engine is what you intended.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm_openai = OpenAI(openai_api_key=OPEN_AI_KEY,engine= \"text-davinci-003\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e068be8e",
      "metadata": {
        "id": "e068be8e"
      },
      "source": [
        "By Default Model is `model_name=text-davinci-003`. You can model/engine name by changing `model_name`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa83ea0",
      "metadata": {
        "id": "2aa83ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "059829cb-b6bc-4ffe-e637-a9c18bd02b62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nFC Barcelona'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "llm_openai(\"Lionel Messi, played for which club?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ef8026",
      "metadata": {
        "id": "00ef8026"
      },
      "source": [
        "###  Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483585cf",
      "metadata": {
        "id": "483585cf"
      },
      "outputs": [],
      "source": [
        "# pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb935993",
      "metadata": {
        "id": "fb935993"
      },
      "outputs": [],
      "source": [
        "## Import Library\n",
        "## Setup keys\n",
        "from langchain import HuggingFaceHub\n",
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b09b5c03",
      "metadata": {
        "id": "b09b5c03"
      },
      "outputs": [],
      "source": [
        "llm_hugging=HuggingFaceHub(repo_id=\"google/flan-t5-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46684acc",
      "metadata": {
        "scrolled": true,
        "id": "46684acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1f6e5e-9e34-4dd6-d2fa-b803f521a61b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFaceHub(cache=None, verbose=False, callbacks=None, callback_manager=None, client=InferenceAPI(api_url='https://api-inference.huggingface.co/pipeline/text2text-generation/google/flan-t5-large', task='text2text-generation', options={'wait_for_model': True, 'use_gpu': False}), repo_id='google/flan-t5-large', task=None, model_kwargs=None, huggingfacehub_api_token=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "llm_hugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87dfe309",
      "metadata": {
        "id": "87dfe309"
      },
      "outputs": [],
      "source": [
        "llm_hugging(\"Lionel Messi, played for which club?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "455f6fa5",
      "metadata": {
        "id": "455f6fa5"
      },
      "source": [
        "\n",
        "### 2. Prompt Templates\n",
        "\n",
        "Lang-chain provides a standard interface for string prompt templates and message `PromptTemplate`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc2e3fe",
      "metadata": {
        "id": "1cc2e3fe"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Translate given text in french {text}?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdee422e",
      "metadata": {
        "id": "fdee422e"
      },
      "outputs": [],
      "source": [
        "print(prompt.format(text=\"Hi how are you\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07a8d476",
      "metadata": {
        "id": "07a8d476"
      },
      "outputs": [],
      "source": [
        "# llm_openai(prompt)\n",
        "\n",
        "############################################\n",
        "# TypeError: Object of type PromptTemplate is not JSON serializable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f4ee92",
      "metadata": {
        "id": "f0f4ee92"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2ef4e1",
      "metadata": {
        "id": "7e2ef4e1"
      },
      "source": [
        "###3. Chains: Combine LLMs and prompts in multi-step workflows\n",
        "\n",
        "Combines multiple models and prompts, allowing them to work together seamlessly within a single application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d6aa3c",
      "metadata": {
        "id": "85d6aa3c"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm_openai, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8e466b",
      "metadata": {
        "id": "0f8e466b"
      },
      "outputs": [],
      "source": [
        "chain.run(\"Hi how are you\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Memory\n",
        "\n",
        "Chains and Agents are stateless, meaning that they treat each incoming query independently, after executing that particular task it forgets the previous conversational unlike in Chatbots where keeping track of conversation is highly important.\n",
        "\n",
        "### 1. ChatMessageHistory\n",
        "Store and Fetch Conversation : Human messages, AI messages"
      ],
      "metadata": {
        "id": "FZyUXpI36cRw"
      },
      "id": "FZyUXpI36cRw"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "history = ChatMessageHistory()\n",
        "\n",
        "history.add_user_message(\"Hi there, I need some help. I want to cancel my Netflix subscription.\")\n",
        "history.add_ai_message(\"I'm sorry to hear that you want to cancel your Netflix subscription. I'll do my best to assist you with that. Can you please provide me with your Netflix account details?\")\n",
        "history.add_user_message(\"Sure, my account email is me_user@email.com]\")\n",
        "history.add_ai_message(\"Thank you for providing your account email. To proceed with the cancellation, I need to verify your identity. Could you please provide the last four digits of the credit card associated with your Netflix account?\")\n",
        "history.add_user_message(\"The last four digits are 1234.\")\n",
        "history.add_ai_message(\"Thank you for the verification.Your Netflix subscription has been successfully canceled. Is there anything else I can assist you with today?\")\n",
        "history.add_user_message(\"No, that's all. Thank you for your help.\")\n",
        "history.add_ai_message(\"You're welcome! If you have any further questions or need assistance in the future, feel free to reach out. Have a great day!\")"
      ],
      "metadata": {
        "id": "mqcJQnyE6f-E"
      },
      "id": "mqcJQnyE6f-E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.messages"
      ],
      "metadata": {
        "id": "kzDJT0b16t0N"
      },
      "id": "kzDJT0b16t0N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.ConversationBufferMemory\n",
        "ChatMessageHistory that extracts the messages in a variable."
      ],
      "metadata": {
        "id": "Bc9D5wlf8N1p"
      },
      "id": "Bc9D5wlf8N1p"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(return_messages=True)\n"
      ],
      "metadata": {
        "id": "BJBQ9sQY8qOO"
      },
      "id": "BJBQ9sQY8qOO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.chat_memory.add_user_message(\"Hi there, I need some help. I want to cancel my Netflix subscription.\")\n",
        "memory.chat_memory.add_user_message(\"I'm sorry to hear that you want to cancel your Netflix subscription. I'll do my best to assist you with that. Can you please provide me with your Netflix account details?\")\n",
        "memory.chat_memory.add_user_message(\"Sure, my account email is me_user@email.com]\")\n",
        "memory.chat_memory.add_user_message(\"Thank you for providing your account email. To proceed with the cancellation, I need to verify your identity. Could you please provide the last four digits of the credit card associated with your Netflix account?\")\n",
        "memory.chat_memory.add_user_message(\"The last four digits are 1234.\")\n",
        "memory.chat_memory.add_user_message(\"Thank you for the verification.Your Netflix subscription has been successfully canceled. Is there anything else I can assist you with today?\")\n",
        "memory.chat_memory.add_user_message(\"No, that's all. Thank you for your help.\")\n",
        "memory.chat_memory.add_user_message(\"You're welcome! If you have any further questions or need assistance in the future, feel free to reach out. Have a great day!\")"
      ],
      "metadata": {
        "id": "ZVHoXt90897t"
      },
      "id": "ZVHoXt90897t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "59x7-HfN86bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca87b7a-b727-4e1a-8267-fc3f8a668ac8"
      },
      "id": "59x7-HfN86bq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Hi there, I need some help. I want to cancel my Netflix subscription.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content=\"I'm sorry to hear that you want to cancel your Netflix subscription. I'll do my best to assist you with that. Can you please provide me with your Netflix account details?\", additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='Sure, my account email is me_user@email.com]', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='Thank you for providing your account email. To proceed with the cancellation, I need to verify your identity. Could you please provide the last four digits of the credit card associated with your Netflix account?', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='The last four digits are 1234.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='Thank you for the verification.Your Netflix subscription has been successfully canceled. Is there anything else I can assist you with today?', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content=\"No, that's all. Thank you for your help.\", additional_kwargs={}, example=False),\n",
              "  HumanMessage(content=\"You're welcome! If you have any further questions or need assistance in the future, feel free to reach out. Have a great day!\", additional_kwargs={}, example=False)]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "\n",
        "llm =OpenAI(openai_api_key=OPEN_AI_KEY,engine= \"text-davinci-003\")\n",
        "conversation = ConversationChain(\n",
        "    llm=llm_openai,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "RSiMMCLA8OM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df90604-fde9-4ed6-c22d-5d065f67f48f"
      },
      "id": "RSiMMCLA8OM5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:WARNING! engine is not default parameter.\n",
            "                    engine was transferred to model_kwargs.\n",
            "                    Please confirm that engine is what you intended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Have you cancelled my Subscription? Plz give me confirmation for the same.\")"
      ],
      "metadata": {
        "id": "YxHW_YAd9gZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4103b3ca-8909-42de-c654-7f28d56f39c2"
      },
      "id": "YxHW_YAd9gZw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Have you cancelled my Subscription? Plz give me confirmation for the same.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yes, I have cancelled your subscription as requested. I can confirm that your subscription has been successfully cancelled and will not be renewed. Is there anything else I can help you with?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI, LLMChain, PromptTemplate"
      ],
      "metadata": {
        "id": "MjdDZm_DwASZ"
      },
      "id": "MjdDZm_DwASZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"You are a chatbot having a conversation with a human.\n",
        "\n",
        "{chat_history}\n",
        "Human: {human_input}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\"],\n",
        "    template=template\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "tzkBoEKjwAXo"
      },
      "id": "tzkBoEKjwAXo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(openai_api_key=OPEN_AI_KEY,engine= \"text-davinci-003\"),\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")"
      ],
      "metadata": {
        "id": "dtIv4qeQwAcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4205c64c-9d01-492a-c7c9-6378534c82da"
      },
      "id": "dtIv4qeQwAcR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:WARNING! engine is not default parameter.\n",
            "                    engine was transferred to model_kwargs.\n",
            "                    Please confirm that engine is what you intended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"Hi! I'm planning a trip to London on July 2023. Can you provide me with some information and recommendations?\")"
      ],
      "metadata": {
        "id": "Fw3DzK3pwQRy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "186465c6-42c7-4419-ace4-adc224515c6b"
      },
      "id": "Fw3DzK3pwQRy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
            "\n",
            "\n",
            "Human: Hi! I'm planning a trip to London on July 2023. Can you provide me with some information and recommendations?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hi there! London is a beautiful city to visit. I recommend that you check out the Tower of London, Big Ben, Buckingham Palace, and the London Eye. Additionally, there are plenty of great restaurants and pubs to explore. Have fun and enjoy your trip!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"I'm mainly interested in sightseeing spots and popular attractions.\")"
      ],
      "metadata": {
        "id": "erUCG8j8-BN5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e4ab683c-19bd-471c-a4f2-69bba6034713"
      },
      "id": "erUCG8j8-BN5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
            "\n",
            "Human: Hi! I'm planning a trip to London on July 2023. Can you provide me with some information and recommendations?\n",
            "AI:  Hi there! London is a beautiful city to visit. I recommend that you check out the Tower of London, Big Ben, Buckingham Palace, and the London Eye. Additionally, there are plenty of great restaurants and pubs to explore. Have fun and enjoy your trip!\n",
            "Human: I'm mainly interested in sightseeing spots and popular attractions.\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Absolutely! London has so much to offer when it comes to sightseeing. In addition to the attractions I mentioned earlier, you should also check out the British Museum, Westminster Abbey, and St. Paul's Cathedral. There are also plenty of parks and gardens for you to explore. Have a great time!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"That's great! I also need information about transportation within the city. \")"
      ],
      "metadata": {
        "id": "dI0j40Xy-gMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "243a9ea2-57d4-4b8e-b46d-9464faf811b7"
      },
      "id": "dI0j40Xy-gMi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
            "\n",
            "Human: Hi! I'm planning a trip to London on July 2023. Can you provide me with some information and recommendations?\n",
            "AI:  Hi there! London is a beautiful city to visit. I recommend that you check out the Tower of London, Big Ben, Buckingham Palace, and the London Eye. Additionally, there are plenty of great restaurants and pubs to explore. Have fun and enjoy your trip!\n",
            "Human: I'm mainly interested in sightseeing spots and popular attractions.\n",
            "AI:  Absolutely! London has so much to offer when it comes to sightseeing. In addition to the attractions I mentioned earlier, you should also check out the British Museum, Westminster Abbey, and St. Paul's Cathedral. There are also plenty of parks and gardens for you to explore. Have a great time!\n",
            "Human: That's great! I also need information about transportation within the city. \n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Of course! The best way to get around London is by taking the Underground, also known as the Tube. It's easy to use and connects most parts of the city. You can also take a bus or taxi, or rent a bike for a more leisurely exploration of the city.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"Ohh I forgot the date ,When I was going to london could you plz tell me?\")"
      ],
      "metadata": {
        "id": "NK4xmKBU-shO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "9aba996c-d640-4409-da10-a62adfee5b84"
      },
      "id": "NK4xmKBU-shO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
            "\n",
            "Human: Hi! I'm planning a trip to London on July 2023. Can you provide me with some information and recommendations?\n",
            "AI:  Hi there! London is a beautiful city to visit. I recommend that you check out the Tower of London, Big Ben, Buckingham Palace, and the London Eye. Additionally, there are plenty of great restaurants and pubs to explore. Have fun and enjoy your trip!\n",
            "Human: I'm mainly interested in sightseeing spots and popular attractions.\n",
            "AI:  Absolutely! London has so much to offer when it comes to sightseeing. In addition to the attractions I mentioned earlier, you should also check out the British Museum, Westminster Abbey, and St. Paul's Cathedral. There are also plenty of parks and gardens for you to explore. Have a great time!\n",
            "Human: That's great! I also need information about transportation within the city. \n",
            "AI:  Of course! The best way to get around London is by taking the Underground, also known as the Tube. It's easy to use and connects most parts of the city. You can also take a bus or taxi, or rent a bike for a more leisurely exploration of the city.\n",
            "Human: Ohh I forgot the date ,When I was going to london could you plz tell me?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' You said you were planning a trip to London on July 2023.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67007307",
      "metadata": {
        "id": "67007307"
      },
      "source": [
        "### 5. Agents: Dynamically Call Chains Based on User Input\n",
        "\n",
        "An agent has access to various tools. Depending on the user input, the agent can then decide which, if any, of these tools to call.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a639c6",
      "metadata": {
        "id": "c6a639c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "5148563a-e2b4-46ac-e857-07d6126a518e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to calculate an exponent\n",
            "Action: Calculator\n",
            "Action Input: 2^8\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 256\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 2^8 = 256\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2^8 = 256'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "tools = load_tools([ \"llm-math\"], llm=llm_openai)\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "agent.run(\"What is 2^8\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}